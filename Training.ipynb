{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train](http://cliparting.com/wp-content/uploads/2016/06/Train-clipart-for-kids-free-free-clipart-images.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1019)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import sys, os, gc, types\n",
    "import time\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append('./utils')\n",
    "from training import cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_paths = [\n",
    "    \"/data/kaggle-instacart\",\n",
    "    \"/Users/jiayou/Dropbox/珺珺的程序/Kaggle/Instacart\",\n",
    "    \"/Users/jiayou/Dropbox/Documents/珺珺的程序/Kaggle/Instacart\"\n",
    "]\n",
    "root = None\n",
    "for p in root_paths:\n",
    "    if os.path.exists(p):\n",
    "        root = p\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'r1'\n",
    "down_sample = 10\n",
    "num_searches = 2\n",
    "boosting_rounds = 100\n",
    "stopping_rounds = 5\n",
    "\n",
    "xgb_params_search = {\n",
    "#     \"learning_rate\"    : lambda: int(10**np.random.uniform(-2, -1) * 1e4) / 1e4,\n",
    "#     \"max_depth\"        : lambda: np.random.randint(3, 7),\n",
    "#     \"min_split_loss\"   : [0, 0.70],\n",
    "#     \"min_child_weight\" : [1, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(down_sample=None):\n",
    "    data = pd.read_csv(os.path.join(root, 'abt.csv'))\n",
    "    \n",
    "    n = data.shape[0]\n",
    "    data['rand_uniform'] = np.random.uniform(0, 1, n)\n",
    "    data['rand_normal'] = np.random.normal(0, 1, n)\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if col in ['user_id', 'product_id', 'order_id']:\n",
    "            continue\n",
    "        if data[col].dtypes == 'float64':\n",
    "            data[col] = data[col].astype('float32')\n",
    "        elif data[col].dtypes == 'int64':\n",
    "            data[col] = data[col].astype('int32')\n",
    "    \n",
    "    train = data.loc[data.eval_set == \"train\",:]\n",
    "    test = data.loc[data.eval_set == \"test\",:]\n",
    "    \n",
    "    if down_sample is not None:\n",
    "        train = train[train.user_id % down_sample == 0]\n",
    "        test = test[test.user_id % down_sample == 0]\n",
    "    \n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = get_data(down_sample)\n",
    "gc.collect()\n",
    "train['reordered'] = train.reordered.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train.drop(['eval_set', 'user_id', 'product_id', 'order_id', 'aisle_id', 'reordered'], axis=1), \n",
    "    train.reordered,\n",
    "    test_size=0, random_state=1019)\n",
    "\n",
    "d_train = xgboost.DMatrix(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_params(default, search):\n",
    "    np.random.seed(int(time.time()))\n",
    "    p = dict(default)\n",
    "    for k, gen in search.items():\n",
    "        v = None\n",
    "        if type(gen) == list:\n",
    "            v = gen[np.random.randint(0, len(gen))]\n",
    "        elif type(gen) == types.LambdaType:\n",
    "            v = gen()\n",
    "        p[k] = v\n",
    "    return p\n",
    "\n",
    "def print_params(params, keys):\n",
    "    print()\n",
    "    print([\"{} = {}\".format(k, params[k]) for k in keys])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['learning_rate = 0.0389', 'max_depth = 3', 'min_split_loss = 0', 'min_child_weight = 1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params_default = {\n",
    "    \"booster\"          : \"gbtree\",\n",
    "    \"tree_method\"      : \"auto\",\n",
    "    \"learning_rate\"    : 0.1,\n",
    "    \"min_split_loss\"   : 0.7, # ?\n",
    "    \"max_depth\"        : 6,\n",
    "    \"min_child_weight\" : 10, # hessian weight\n",
    "    \"subsample\"        : 0.7,\n",
    "    \"colsample_bytree\" : 0.9,\n",
    "    \"reg_alpha\"        : 2e-05,\n",
    "    \"reg_lambda\"       : 10,\n",
    "    \n",
    "    \"objective\"        : \"reg:logistic\",\n",
    "    \"eval_metric\"      : \"logloss\"\n",
    "}\n",
    "\n",
    "xgb_params = get_params(default=xgb_params_default, search=xgb_params_search)\n",
    "print_params(xgb_params, keys=xgb_params_search.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Running random param search with cross validation...')\n",
    "results = []\n",
    "for i in range(num_searches):\n",
    "    xgb_params = get_params(default=xgb_params_default, search=xgb_params_search)\n",
    "    print_params(xgb_params, keys=xgb_params_search.keys())\n",
    "    h, cvfolds = cv(\n",
    "        xgb_params, d_train, num_boost_round=boosting_rounds, nfold=4,\n",
    "        metrics={'logloss'}, seed = 1019,\n",
    "        callbacks=[\n",
    "            xgboost.callback.print_evaluation(show_stdv=True),\n",
    "            xgboost.callback.early_stop(stopping_rounds=stopping_rounds)\n",
    "        ])\n",
    "    results.append([xgb_params, h])\n",
    "    \n",
    "    for f in cvfolds:\n",
    "        plt.figure()\n",
    "        xgboost.plot_importance(f.bst)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save search results\n",
    "params = []\n",
    "histories = []\n",
    "for i in range(num_searches):\n",
    "    p = dict(results[i][0])\n",
    "    h = results[i][1].copy()\n",
    "    \n",
    "    p['search_id'] = i\n",
    "    params.append(p)\n",
    "    \n",
    "    h['search_id'] = i\n",
    "    h['boost_round'] = range(h.shape[0])\n",
    "    histories.append(h)\n",
    "    \n",
    "p = pd.DataFrame(params)\n",
    "p.to_csv(os.path.join(root, 'search-{}-params.csv'.format(name)), index=False)\n",
    "\n",
    "h = pd.concat(histories)\n",
    "h.to_csv(os.path.join(root, 'search-{}-histories.csv'.format(name)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# watchlist= [(d_train, \"train\")]\n",
    "# bst = xgboost.train(params=xgb_params, dtrain=d_train, num_boost_round=80, evals=watchlist, verbose_eval=10)\n",
    "# xgboost.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "d_test = xgboost.DMatrix(test.drop(['eval_set', 'user_id', 'order_id', 'aisle_id', 'reordered', 'product_id'], axis=1))\n",
    "pred = bst.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Thresholding\n",
    "test['reordered'] = (pred > 0.21).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Submission file\n",
    "test['product_id'] = test.product_id.astype(str)\n",
    "submit = test[test.reordered == 1]\n",
    "    .groupby('order_id')['product_id']\n",
    "    .agg([lambda x: ' '.join(set(x))])\n",
    "    .reset_index()\n",
    "sample_submission = pd.read_csv(os.path.join(root, 'sample_submission.csv'))\n",
    "submit.columns = sample_submission.columns.tolist()\n",
    "submit_final = sample_submission[['order_id']].merge(submit, how='left').fillna('None')\n",
    "submit_final.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stats\n",
    "print('{} pred orders; {} of them non-empty'.format(submit_final.shape[0], submit.shape[0]))\n",
    "empty_order_ratio = (submit_final.shape[0] - submit.shape[0]) * 100. / submit_final.shape[0]\n",
    "print('Empty order ratio is {:.2f}%'.format(empty_order_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
