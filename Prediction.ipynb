{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train](http://3.bp.blogspot.com/-Nt8l3SY2UiY/VHHLVsm8cFI/AAAAAAAAJGg/sPXvFN41aaU/s1600/contr%C3%A1rio.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1019)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import sys, os, gc, types\n",
    "import time\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append('./utils')\n",
    "\n",
    "from training import cv, train\n",
    "from plotting import plot_importance\n",
    "from data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_paths = [\n",
    "    \"/data/kaggle-instacart\",\n",
    "    \"/Users/jiayou/Dropbox/珺珺的程序/Kaggle/Instacart\",\n",
    "    \"/Users/jiayou/Dropbox/Documents/珺珺的程序/Kaggle/Instacart\"\n",
    "]\n",
    "root = None\n",
    "for p in root_paths:\n",
    "    if os.path.exists(p):\n",
    "        root = p\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class F1Optimizer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_expectations(P, pNone=None):\n",
    "        expectations = []\n",
    "        P = np.sort(P)[::-1]\n",
    "\n",
    "        n = np.array(P).shape[0]\n",
    "        DP_C = np.zeros((n + 2, n + 1))\n",
    "        if pNone is None:\n",
    "            pNone = (1.0 - P).prod()\n",
    "\n",
    "        DP_C[0][0] = 1.0\n",
    "        for j in range(1, n):\n",
    "            DP_C[0][j] = (1.0 - P[j - 1]) * DP_C[0, j - 1]\n",
    "\n",
    "        for i in range(1, n + 1):\n",
    "            DP_C[i, i] = DP_C[i - 1, i - 1] * P[i - 1]\n",
    "            for j in range(i + 1, n + 1):\n",
    "                DP_C[i, j] = P[j - 1] * DP_C[i - 1, j - 1] + (1.0 - P[j - 1]) * DP_C[i, j - 1]\n",
    "\n",
    "        DP_S = np.zeros((2 * n + 1,))\n",
    "        DP_SNone = np.zeros((2 * n + 1,))\n",
    "        for i in range(1, 2 * n + 1):\n",
    "            DP_S[i] = 1. / (1. * i)\n",
    "            DP_SNone[i] = 1. / (1. * i + 1)\n",
    "        for k in range(n + 1)[::-1]:\n",
    "            f1 = 0\n",
    "            f1None = 0\n",
    "            for k1 in range(n + 1):\n",
    "                f1 += 2 * k1 * DP_C[k1][k] * DP_S[k + k1]\n",
    "                f1None += 2 * k1 * DP_C[k1][k] * DP_SNone[k + k1]\n",
    "            for i in range(1, 2 * k - 1):\n",
    "                DP_S[i] = (1 - P[k - 1]) * DP_S[i] + P[k - 1] * DP_S[i + 1]\n",
    "                DP_SNone[i] = (1 - P[k - 1]) * DP_SNone[i] + P[k - 1] * DP_SNone[i + 1]\n",
    "            expectations.append([f1None + 2 * pNone / (2 + k), f1])\n",
    "\n",
    "        return np.array(expectations[::-1]).T\n",
    "\n",
    "    @staticmethod\n",
    "    def maximize_expectation(P, pNone=None):\n",
    "        expectations = F1Optimizer.get_expectations(P, pNone)\n",
    "\n",
    "        ix_max = np.unravel_index(expectations.argmax(), expectations.shape)\n",
    "        max_f1 = expectations[ix_max]\n",
    "\n",
    "        predNone = True if ix_max[0] == 0 else False\n",
    "        best_k = ix_max[1]\n",
    "\n",
    "        return best_k, predNone, max_f1\n",
    "\n",
    "    @staticmethod\n",
    "    def _F1(tp, fp, fn):\n",
    "        return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "    @staticmethod\n",
    "    def _Fbeta(tp, fp, fn, beta=1.0):\n",
    "        beta_squared = beta ** 2\n",
    "        return (1.0 + beta_squared) * tp / ((1.0 + beta_squared) * tp + fp + beta_squared * fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(bst):\n",
    "    d_test = xgboost.DMatrix(\n",
    "        test.drop(['eval_set', 'order_id', 'reordered', 'product_id'], axis=1))\n",
    "    return bst.predict(d_test)\n",
    "\n",
    "def ensemble(preds):\n",
    "    # Average ensemble\n",
    "    r = None\n",
    "    for p in preds:\n",
    "        if r is None:\n",
    "            r = p\n",
    "        else:\n",
    "            r += p\n",
    "    return r / len(preds)\n",
    "\n",
    "def ensemble_predict(bsts):\n",
    "    preds = []\n",
    "    for bst in bsts:\n",
    "        preds.append(predict(bst))\n",
    "    return ensemble(preds)\n",
    "\n",
    "def thresholding(pred):\n",
    "    return (pred > 0.21).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'v4-r0'\n",
    "train_name = 'v3-r1'\n",
    "down_sample = 10\n",
    "num_searches = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsts = []\n",
    "for i in range(num_searches):\n",
    "    bsts.append(xgboost.Booster(model_file=os.path.join(root, 'train-{}-n{}.bst'.format(train_name, i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = Data.test(down_sample=down_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with F1 optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['reordered'] = ensemble_predict([bst for bst in bsts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiayou/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "test_result = test[['product_id', 'order_id', 'reordered']]\n",
    "test_result.sort_values(by = 'order_id', axis = 0, ascending = True, inplace = True)\n",
    "test_result.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18825164437294006"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_none = pd.read_csv(os.path.join(root, 'none_prediction.csv'), index_col='order_id')\n",
    "test_none.loc[1980631, 'is_none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_wf1(w_none = True):\n",
    "    test_order_id = test_result.order_id.unique()\n",
    "    start_time = time.time()\n",
    "    submission = []\n",
    "    \n",
    "    start, end, i = 0, 0, 0\n",
    "    while start < len(test_result):\n",
    "        current_id = test_result.loc[start, 'order_id']\n",
    "        while end < len(test_result) and current_id == test_result.loc[end, 'order_id']:\n",
    "            end += 1\n",
    "        df = test_result.iloc[start:end]\n",
    "        df.sort_values(by = 'reordered', axis = 0, ascending = False, inplace = True)\n",
    "        \n",
    "        if w_none:\n",
    "            p_none = test_none.loc[current_id, 'is_none']\n",
    "            best_k, predNone, _ = F1Optimizer.maximize_expectation(df.reordered, p_none)\n",
    "        else:\n",
    "            best_k, predNone, _ = F1Optimizer.maximize_expectation(df.reordered)    \n",
    "            \n",
    "        if best_k == 0:\n",
    "            submission.append({'order_id': current_id, 'products': 'None'})\n",
    "        else:\n",
    "            df.product_id = df.product_id.astype(str)\n",
    "            reordered_product = ' '.join(df.product_id[:best_k])\n",
    "            if predNone:\n",
    "                reordered_product += ' None'\n",
    "            submission.append({'order_id': current_id, 'products': reordered_product})\n",
    "            \n",
    "        if i % 10 == 0:\n",
    "            print('{} predictions have been saved'.format(i))\n",
    "            remaining_time = (time.time()-start_time) / (i+1) * (len(test_order_id) - i)\n",
    "            print('{:.2f}s remaining'.format(remaining_time))\n",
    "            \n",
    "        start = end\n",
    "        i += 1\n",
    "        \n",
    "    return submission\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiayou/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jiayou/anaconda/lib/python3.6/site-packages/pandas/core/generic.py:2773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 predictions have been saved\n",
      "107.86s remaining\n",
      "10 predictions have been saved\n",
      "228.78s remaining\n",
      "20 predictions have been saved\n",
      "172.30s remaining\n",
      "30 predictions have been saved\n",
      "228.33s remaining\n",
      "40 predictions have been saved\n",
      "213.57s remaining\n",
      "50 predictions have been saved\n",
      "215.59s remaining\n",
      "60 predictions have been saved\n",
      "206.22s remaining\n",
      "70 predictions have been saved\n",
      "198.99s remaining\n",
      "80 predictions have been saved\n",
      "193.83s remaining\n",
      "90 predictions have been saved\n",
      "183.52s remaining\n",
      "100 predictions have been saved\n",
      "173.20s remaining\n",
      "110 predictions have been saved\n",
      "185.67s remaining\n",
      "120 predictions have been saved\n",
      "174.75s remaining\n",
      "130 predictions have been saved\n",
      "171.89s remaining\n",
      "140 predictions have been saved\n",
      "165.92s remaining\n",
      "150 predictions have been saved\n",
      "175.78s remaining\n",
      "160 predictions have been saved\n",
      "172.30s remaining\n",
      "170 predictions have been saved\n",
      "170.88s remaining\n",
      "180 predictions have been saved\n",
      "165.96s remaining\n",
      "190 predictions have been saved\n",
      "165.20s remaining\n",
      "200 predictions have been saved\n",
      "177.23s remaining\n",
      "210 predictions have been saved\n",
      "174.73s remaining\n",
      "220 predictions have been saved\n",
      "169.88s remaining\n",
      "230 predictions have been saved\n",
      "165.22s remaining\n",
      "240 predictions have been saved\n",
      "159.49s remaining\n",
      "250 predictions have been saved\n",
      "158.69s remaining\n",
      "260 predictions have been saved\n",
      "155.88s remaining\n",
      "270 predictions have been saved\n",
      "152.41s remaining\n",
      "280 predictions have been saved\n",
      "147.52s remaining\n",
      "290 predictions have been saved\n",
      "142.69s remaining\n",
      "300 predictions have been saved\n",
      "140.72s remaining\n",
      "310 predictions have been saved\n",
      "138.40s remaining\n",
      "320 predictions have been saved\n",
      "139.11s remaining\n",
      "330 predictions have been saved\n",
      "135.45s remaining\n",
      "340 predictions have been saved\n",
      "131.51s remaining\n",
      "350 predictions have been saved\n",
      "127.88s remaining\n",
      "360 predictions have been saved\n",
      "123.37s remaining\n",
      "370 predictions have been saved\n",
      "119.88s remaining\n",
      "380 predictions have been saved\n",
      "117.87s remaining\n",
      "390 predictions have been saved\n",
      "115.49s remaining\n",
      "400 predictions have been saved\n",
      "113.06s remaining\n",
      "410 predictions have been saved\n",
      "109.22s remaining\n",
      "420 predictions have been saved\n",
      "106.77s remaining\n",
      "430 predictions have been saved\n",
      "103.86s remaining\n",
      "440 predictions have been saved\n",
      "99.95s remaining\n",
      "450 predictions have been saved\n",
      "96.59s remaining\n",
      "460 predictions have been saved\n",
      "94.81s remaining\n",
      "470 predictions have been saved\n",
      "91.67s remaining\n",
      "480 predictions have been saved\n",
      "88.38s remaining\n",
      "490 predictions have been saved\n",
      "84.86s remaining\n",
      "500 predictions have been saved\n",
      "81.32s remaining\n",
      "510 predictions have been saved\n",
      "78.11s remaining\n",
      "520 predictions have been saved\n",
      "75.56s remaining\n",
      "530 predictions have been saved\n",
      "72.44s remaining\n",
      "540 predictions have been saved\n",
      "69.01s remaining\n",
      "550 predictions have been saved\n",
      "65.86s remaining\n",
      "560 predictions have been saved\n",
      "62.75s remaining\n",
      "570 predictions have been saved\n",
      "62.14s remaining\n",
      "580 predictions have been saved\n",
      "59.03s remaining\n",
      "590 predictions have been saved\n",
      "55.89s remaining\n",
      "600 predictions have been saved\n",
      "53.06s remaining\n",
      "610 predictions have been saved\n",
      "50.12s remaining\n",
      "620 predictions have been saved\n",
      "47.43s remaining\n",
      "630 predictions have been saved\n",
      "44.68s remaining\n",
      "640 predictions have been saved\n",
      "41.64s remaining\n",
      "650 predictions have been saved\n",
      "38.47s remaining\n",
      "660 predictions have been saved\n",
      "35.39s remaining\n",
      "670 predictions have been saved\n",
      "32.45s remaining\n",
      "680 predictions have been saved\n",
      "29.51s remaining\n",
      "690 predictions have been saved\n",
      "26.47s remaining\n",
      "700 predictions have been saved\n",
      "23.77s remaining\n",
      "710 predictions have been saved\n",
      "20.85s remaining\n",
      "720 predictions have been saved\n",
      "17.97s remaining\n",
      "730 predictions have been saved\n",
      "15.42s remaining\n",
      "740 predictions have been saved\n",
      "12.70s remaining\n",
      "750 predictions have been saved\n",
      "9.78s remaining\n",
      "760 predictions have been saved\n",
      "6.99s remaining\n",
      "770 predictions have been saved\n",
      "4.11s remaining\n",
      "780 predictions have been saved\n",
      "1.18s remaining\n"
     ]
    }
   ],
   "source": [
    "submission = predict_wf1()\n",
    "submission_df = pd.DataFrame(data = submission)\n",
    "submission_df.sort_values(by = 'order_id', axis = 0, ascending = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37890</td>\n",
       "      <td>24852 23102 34024 45 38849 16797 4920 6244 477...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>162620</td>\n",
       "      <td>30571 21137 27344 24852 32864 48415 45007 19057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>216680</td>\n",
       "      <td>16797 14702 27966 13176 39877 14378 26604 4506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235350</td>\n",
       "      <td>21137 24852 19171 39275 43988 39928 47144 4923...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>387510</td>\n",
       "      <td>21137 24852 27845 18465 13176 43961 24838 3868...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id                                           products\n",
       "15     37890  24852 23102 34024 45 38849 16797 4920 6244 477...\n",
       "29    162620    30571 21137 27344 24852 32864 48415 45007 19057\n",
       "14    216680  16797 14702 27966 13176 39877 14378 26604 4506...\n",
       "3     235350  21137 24852 19171 39275 43988 39928 47144 4923...\n",
       "13    387510  21137 24852 27845 18465 13176 43961 24838 3868..."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission-{}.csv\".format(name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "# test['reordered'] = thresholding(ensemble_predict([bst for bst in bsts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Submission file\n",
    "# test['product_id'] = test.product_id.astype(str)\n",
    "# submit = test[test.reordered == 1].groupby('order_id')['product_id'].agg([lambda x: ' '.join(set(x))]).reset_index()\n",
    "# sample_submission = pd.read_csv(os.path.join(root, 'sample_submission.csv'))\n",
    "# submit.columns = sample_submission.columns.tolist()\n",
    "# submit_final = sample_submission[['order_id']].merge(submit, how='left').fillna('None')\n",
    "# submit_final.to_csv(\"submission-{}.csv\".format(name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000 pred orders; 743 of them non-empty\n",
      "Empty order ratio is 99.01%\n"
     ]
    }
   ],
   "source": [
    "# # Stats\n",
    "# print('{} pred orders; {} of them non-empty'.format(submit_final.shape[0], submit.shape[0]))\n",
    "# empty_order_ratio = (submit_final.shape[0] - submit.shape[0]) * 100. / submit_final.shape[0]\n",
    "# print('Empty order ratio is {:.2f}%'.format(empty_order_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
