{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train](http://3.bp.blogspot.com/-Nt8l3SY2UiY/VHHLVsm8cFI/AAAAAAAAJGg/sPXvFN41aaU/s1600/contr%C3%A1rio.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1019)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import sys, os, gc, types\n",
    "import time\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append('./utils')\n",
    "\n",
    "from training import cv, train\n",
    "from plotting import plot_importance\n",
    "from data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_paths = [\n",
    "    \"/data/kaggle-instacart\",\n",
    "    \"/Users/jiayou/Dropbox/珺珺的程序/Kaggle/Instacart\",\n",
    "    \"/Users/jiayou/Dropbox/Documents/珺珺的程序/Kaggle/Instacart\"\n",
    "]\n",
    "root = None\n",
    "for p in root_paths:\n",
    "    if os.path.exists(p):\n",
    "        root = p\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class F1Optimizer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_expectations(P, pNone=None):\n",
    "        expectations = []\n",
    "        P = np.sort(P)[::-1]\n",
    "\n",
    "        n = np.array(P).shape[0]\n",
    "        DP_C = np.zeros((n + 2, n + 1))\n",
    "        if pNone is None:\n",
    "            pNone = (1.0 - P).prod()\n",
    "\n",
    "        DP_C[0][0] = 1.0\n",
    "        for j in range(1, n):\n",
    "            DP_C[0][j] = (1.0 - P[j - 1]) * DP_C[0, j - 1]\n",
    "\n",
    "        for i in range(1, n + 1):\n",
    "            DP_C[i, i] = DP_C[i - 1, i - 1] * P[i - 1]\n",
    "            for j in range(i + 1, n + 1):\n",
    "                DP_C[i, j] = P[j - 1] * DP_C[i - 1, j - 1] + (1.0 - P[j - 1]) * DP_C[i, j - 1]\n",
    "\n",
    "        DP_S = np.zeros((2 * n + 1,))\n",
    "        DP_SNone = np.zeros((2 * n + 1,))\n",
    "        for i in range(1, 2 * n + 1):\n",
    "            DP_S[i] = 1. / (1. * i)\n",
    "            DP_SNone[i] = 1. / (1. * i + 1)\n",
    "        for k in range(n + 1)[::-1]:\n",
    "            f1 = 0\n",
    "            f1None = 0\n",
    "            for k1 in range(n + 1):\n",
    "                f1 += 2 * k1 * DP_C[k1][k] * DP_S[k + k1]\n",
    "                f1None += 2 * k1 * DP_C[k1][k] * DP_SNone[k + k1]\n",
    "            for i in range(1, 2 * k - 1):\n",
    "                DP_S[i] = (1 - P[k - 1]) * DP_S[i] + P[k - 1] * DP_S[i + 1]\n",
    "                DP_SNone[i] = (1 - P[k - 1]) * DP_SNone[i] + P[k - 1] * DP_SNone[i + 1]\n",
    "            expectations.append([f1None + 2 * pNone / (2 + k), f1])\n",
    "\n",
    "        return np.array(expectations[::-1]).T\n",
    "\n",
    "    @staticmethod\n",
    "    def maximize_expectation(P, pNone=None):\n",
    "        expectations = F1Optimizer.get_expectations(P, pNone)\n",
    "\n",
    "        ix_max = np.unravel_index(expectations.argmax(), expectations.shape)\n",
    "        max_f1 = expectations[ix_max]\n",
    "\n",
    "        predNone = True if ix_max[0] == 0 else False\n",
    "        best_k = ix_max[1]\n",
    "\n",
    "        return best_k, predNone, max_f1\n",
    "\n",
    "    @staticmethod\n",
    "    def _F1(tp, fp, fn):\n",
    "        return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "    @staticmethod\n",
    "    def _Fbeta(tp, fp, fn, beta=1.0):\n",
    "        beta_squared = beta ** 2\n",
    "        return (1.0 + beta_squared) * tp / ((1.0 + beta_squared) * tp + fp + beta_squared * fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ensemble(preds):\n",
    "    # Average ensemble\n",
    "    r = None\n",
    "    for p in preds:\n",
    "        if r is None:\n",
    "            r = p\n",
    "        else:\n",
    "            r += p\n",
    "    return r / len(preds)\n",
    "\n",
    "def ensemble_predict(bsts, test):\n",
    "    dtest = xgboost.DMatrix(\n",
    "        test.drop(['eval_set', 'order_id', 'reordered', 'product_id'], axis=1))\n",
    "    preds = []\n",
    "    for bst in bsts:\n",
    "        preds.append(bst.predict(dtest))\n",
    "    return ensemble(preds)\n",
    "\n",
    "def thresholding(pred):\n",
    "    return (pred > 0.21).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def order_agg(test_result, test_none):\n",
    "    test_result.sort_values(by = 'order_id', axis = 0, ascending = True, inplace = True)\n",
    "    test_result.reset_index(drop = True, inplace = True)\n",
    "    test_order_id = test_result.order_id.unique()\n",
    "\n",
    "    start_time = time.time()\n",
    "    submission = []\n",
    "\n",
    "    start, end, i = 0, 0, 0\n",
    "    while start < len(test_result):\n",
    "        current_id = test_result.loc[start, 'order_id']\n",
    "        while end < len(test_result) and current_id == test_result.loc[end, 'order_id']:\n",
    "            end += 1\n",
    "        df = test_result.iloc[start:end]\n",
    "        df.sort_values(by = 'reordered', axis = 0, ascending = False, inplace = True)\n",
    "\n",
    "        if test_none is not None:\n",
    "            p_none = test_none.loc[current_id, 'is_none']\n",
    "            best_k, predNone, _ = F1Optimizer.maximize_expectation(df.reordered, p_none)\n",
    "        else:\n",
    "            best_k, predNone, _ = F1Optimizer.maximize_expectation(df.reordered)    \n",
    "\n",
    "        if best_k == 0:\n",
    "            submission.append({'order_id': current_id, 'products': 'None'})\n",
    "        else:\n",
    "            df.product_id = df.product_id.astype(str)\n",
    "            reordered_product = ' '.join(df.product_id[:best_k])\n",
    "            if predNone:\n",
    "                reordered_product += ' None'\n",
    "            submission.append({'order_id': current_id, 'products': reordered_product})\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('{} predictions have been saved'.format(i))\n",
    "            remaining_time = (time.time()-start_time) / (i+1) * (len(test_order_id) - i)\n",
    "            print('{:.2f}s remaining'.format(remaining_time))\n",
    "\n",
    "        start = end\n",
    "        i += 1\n",
    "\n",
    "    return pd.DataFrame(data = submission)\n",
    "    \n",
    "def process_shard(name, shard=0, nshards=1, down_sample=None):\n",
    "    global alltest\n",
    "    test = alltest[alltest.order_id % nshards == shard]\n",
    "\n",
    "    global bsts\n",
    "    test['reordered'] = ensemble_predict(bsts, test)\n",
    "\n",
    "    test_result = test[['product_id', 'order_id', 'reordered']]\n",
    "    test_none = pd.read_csv(os.path.join(root, 'none_prediction.csv'), index_col='order_id')\n",
    "    \n",
    "    submission_df = order_agg(test_result, test_none)\n",
    "    \n",
    "    submission_df.to_csv(os.path.join(root, \"submission-{}-s{}.csv\".format(name, shard)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "name = 'v5-r2'\n",
    "\n",
    "# model\n",
    "train_name = 'v5-r2'\n",
    "num_searches = 1\n",
    "bsts = []\n",
    "for i in range(num_searches):\n",
    "    bsts.append(xgboost.Booster(model_file=os.path.join(root, 'train-{}-n{}.bst'.format(train_name, i))))\n",
    "\n",
    "# test data\n",
    "down_sample = None\n",
    "alltest = Data.test(down_sample=down_sample)\n",
    "    \n",
    "nshards = 32\n",
    "jobs = []\n",
    "for s in range(nshards):\n",
    "    p = Process(target=process_shard, args=(name, s, nshards, down_sample))\n",
    "    p.start()\n",
    "    jobs.append(p)\n",
    "    \n",
    "for p in jobs:\n",
    "    p.join()\n",
    "\n",
    "print(\"\\n\\nShards done.\")\n",
    "\n",
    "subs = []\n",
    "for s in range(nshards):\n",
    "    subs.append(pd.read_csv(os.path.join(root, \"submission-{}-s{}.csv\".format(name, s))))\n",
    "\n",
    "submission_df = pd.concat(subs)\n",
    "submission_df.sort_values(by = 'order_id', axis = 0, ascending = True, inplace = True)\n",
    "submission_df.to_csv(os.path.join(root, \"submission-{}.csv\".format(name)), index=False)\n",
    "\n",
    "for s in range(nshards):\n",
    "    os.remove(os.path.join(root, \"submission-{}-s{}.csv\".format(name, s)))\n",
    "    \n",
    "print(\"\\n\\nAll done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "# test['reordered'] = thresholding(ensemble_predict([bst for bst in bsts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Submission file\n",
    "# test['product_id'] = test.product_id.astype(str)\n",
    "# submit = test[test.reordered == 1].groupby('order_id')['product_id'].agg([lambda x: ' '.join(set(x))]).reset_index()\n",
    "# sample_submission = pd.read_csv(os.path.join(root, 'sample_submission.csv'))\n",
    "# submit.columns = sample_submission.columns.tolist()\n",
    "# submit_final = sample_submission[['order_id']].merge(submit, how='left').fillna('None')\n",
    "# submit_final.to_csv(\"submission-{}.csv\".format(name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000 pred orders; 743 of them non-empty\n",
      "Empty order ratio is 99.01%\n"
     ]
    }
   ],
   "source": [
    "# # Stats\n",
    "# print('{} pred orders; {} of them non-empty'.format(submit_final.shape[0], submit.shape[0]))\n",
    "# empty_order_ratio = (submit_final.shape[0] - submit.shape[0]) * 100. / submit_final.shape[0]\n",
    "# print('Empty order ratio is {:.2f}%'.format(empty_order_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
